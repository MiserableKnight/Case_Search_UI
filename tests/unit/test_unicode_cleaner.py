"""
UnicodeCleanerå•å…ƒæµ‹è¯•

æµ‹è¯•Unicodeå­—ç¬¦æ¸…æ´—å™¨çš„å„ç§åŠŸèƒ½
"""

import pytest
import pandas as pd
from app.utils.unicode_cleaner import UnicodeCleaner


class TestUnicodeCleaner:
    """UnicodeCleaneræµ‹è¯•ç±»"""

    def setup_method(self):
        """æ¯ä¸ªæµ‹è¯•æ–¹æ³•å‰æ‰§è¡Œ"""
        self.cleaner = UnicodeCleaner()

    # ==================== clean_textæµ‹è¯• ====================

    def test_clean_text_normal_string(self):
        """æµ‹è¯•æ¸…æ´—æ™®é€šå­—ç¬¦ä¸²"""
        text = "è¿™æ˜¯ä¸€ä¸ªæ­£å¸¸çš„æ–‡æœ¬å­—ç¬¦ä¸²"
        result = self.cleaner.clean_text(text)
        assert result == text

    def test_clean_text_with_bidirectional_chars(self):
        """æµ‹è¯•æ¸…æ´—åŒå‘æ–‡æœ¬æ§åˆ¶å­—ç¬¦"""
        text = "æ­£å¸¸æ–‡æœ¬\u200e\u200f\u202a\u202bæ–‡æœ¬"
        expected = "æ­£å¸¸æ–‡æœ¬æ–‡æœ¬"
        result = self.cleaner.clean_text(text)
        assert result == expected

    def test_clean_text_with_control_chars(self):
        """æµ‹è¯•æ¸…æ´—æ§åˆ¶å­—ç¬¦"""
        text = "æ–‡æœ¬\x00\x01\x02\x03ä¸­é—´\x7f\x8f\x9f"
        expected = "æ–‡æœ¬ä¸­é—´"
        result = self.cleaner.clean_text(text)
        assert result == expected

    def test_clean_text_with_zero_width_chars(self):
        """æµ‹è¯•æ¸…æ´—é›¶å®½å­—ç¬¦"""
        text = "æ–‡æœ¬\u200b\u200c\u200d\u2060\ufeffä¸­é—´"
        expected = "æ–‡æœ¬ä¸­é—´"
        result = self.cleaner.clean_text(text)
        assert result == expected

    def test_clean_text_none(self):
        """æµ‹è¯•æ¸…æ´—Noneå€¼"""
        result = self.cleaner.clean_text(None)
        assert result == ""

    def test_clean_text_nan(self):
        """æµ‹è¯•æ¸…æ´—NaNå€¼"""
        result = self.cleaner.clean_text(float("nan"))
        assert result == ""

    def test_clean_text_pd_na(self):
        """æµ‹è¯•æ¸…æ´—pandas NAå€¼"""
        result = self.cleaner.clean_text(pd.NA)
        assert result == ""

    def test_clean_text_non_string_type(self):
        """æµ‹è¯•æ¸…æ´—éå­—ç¬¦ä¸²ç±»å‹"""
        result = self.cleaner.clean_text(12345)
        assert result == "12345"

    def test_clean_text_strip_whitespace(self):
        """æµ‹è¯•ç§»é™¤é¦–å°¾ç©ºæ ¼"""
        text = "  æ–‡æœ¬å†…å®¹  "
        result = self.cleaner.clean_text(text)
        assert result == "æ–‡æœ¬å†…å®¹"

    def test_clean_text_mixed_pollution(self):
        """æµ‹è¯•æ··åˆæ±¡æŸ“ç±»å‹"""
        text = "\u200eæ–‡æœ¬\x00\u200bå†…å®¹\u202a\u200f\x7f\u2060"
        expected = "æ–‡æœ¬å†…å®¹"
        result = self.cleaner.clean_text(text)
        assert result == expected

    def test_clean_text_preserve_newlines(self):
        """æµ‹è¯•ä¿ç•™æ¢è¡Œç¬¦ï¼ˆæŸäº›æ§åˆ¶å­—ç¬¦åº”ä¿ç•™ï¼‰"""
        text = "ç¬¬ä¸€è¡Œ\nç¬¬äºŒè¡Œ\tåˆ¶è¡¨ç¬¦\rå›è½¦"
        result = self.cleaner.clean_text(text)
        assert "\n" not in result  # æ¢è¡Œç¬¦åº”è¯¥è¢«ç§»é™¤
        assert "\t" not in result  # åˆ¶è¡¨ç¬¦åº”è¯¥è¢«ç§»é™¤

    # ==================== clean_dataframeæµ‹è¯• ====================

    def test_clean_dataframe_normal(self, sample_dataframe):
        """æµ‹è¯•æ¸…æ´—æ™®é€šDataFrame"""
        result = self.cleaner.clean_dataframe(sample_dataframe)
        assert result is not None
        assert len(result) == len(sample_dataframe)
        assert result.shape == sample_dataframe.shape

    def test_clean_dataframe_with_specified_columns(self, sample_dataframe):
        """æµ‹è¯•æ¸…æ´—æŒ‡å®šåˆ—"""
        result = self.cleaner.clean_dataframe(sample_dataframe, columns=["åˆ—1", "åˆ—2"])
        assert len(result) == len(sample_dataframe)

    def test_clean_dataframe_empty(self, empty_dataframe):
        """æµ‹è¯•æ¸…æ´—ç©ºDataFrame"""
        result = self.cleaner.clean_dataframe(empty_dataframe)
        assert result.empty

    def test_clean_dataframe_none(self):
        """æµ‹è¯•æ¸…æ´—Noneè¾“å…¥"""
        result = self.cleaner.clean_dataframe(None)
        assert result is None

    def test_clean_dataframe_with_polluted_data(self, case_data_with_pollution):
        """æµ‹è¯•æ¸…æ´—åŒ…å«æ±¡æŸ“çš„DataFrame"""
        result = self.cleaner.clean_dataframe(case_data_with_pollution)
        # æ£€æŸ¥æ ‡é¢˜åˆ—ä¸­æ²¡æœ‰Unicodeå­—ç¬¦
        assert "\u200f" not in result.iloc[0]["æ ‡é¢˜"]
        assert "\u200d" not in result.iloc[2]["æ ‡é¢˜"]

    def test_clean_dataframe_with_null_values(self, null_values_dataframe):
        """æµ‹è¯•æ¸…æ´—åŒ…å«ç©ºå€¼çš„DataFrame"""
        result = self.cleaner.clean_dataframe(null_values_dataframe)
        assert len(result) == len(null_values_dataframe)

    def test_clean_dataframe_non_object_columns(self):
        """æµ‹è¯•åªå¤„ç†objectç±»å‹çš„åˆ—"""
        df = pd.DataFrame({
            "æ–‡æœ¬åˆ—": ["å€¼1", "å€¼2"],
            "æ•°å­—åˆ—": [1, 2],
            "æ—¥æœŸåˆ—": pd.to_datetime(["2023-01-01", "2023-01-02"]),
        })
        result = self.cleaner.clean_dataframe(df)
        # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½è¢«å¤„ç†
        assert len(result.columns) == len(df.columns)

    # ==================== clean_excel_fileæµ‹è¯• ====================

    def test_clean_excel_file(self, sample_excel_file, temp_output_dir):
        """æµ‹è¯•æ¸…æ´—Excelæ–‡ä»¶"""
        output_path = temp_output_dir / "cleaned.xlsx"
        result = self.cleaner.clean_excel_file(str(sample_excel_file), str(output_path))

        assert Path(result).exists()
        assert result == str(output_path)

        # éªŒè¯æ¸…æ´—åçš„æ•°æ®
        cleaned_df = pd.read_excel(result)
        assert len(cleaned_df) > 0

    def test_clean_excel_file_auto_output_name(self, sample_excel_file, temp_output_dir):
        """æµ‹è¯•è‡ªåŠ¨ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å"""
        result = self.cleaner.clean_excel_file(str(sample_excel_file))
        assert Path(result).exists()
        assert "_cleaned" in result

    def test_clean_excel_file_invalid_path(self):
        """æµ‹è¯•æ¸…æ´—ä¸å­˜åœ¨çš„æ–‡ä»¶"""
        with pytest.raises(Exception):
            self.cleaner.clean_excel_file("nonexistent_file.xlsx")

    # ==================== detect_unicode_pollutionæµ‹è¯• ====================

    def test_detect_pollution_no_pollution(self):
        """æµ‹è¯•æ£€æµ‹æ— æ±¡æŸ“çš„æ–‡æœ¬"""
        result = self.cleaner.detect_unicode_pollution("æ­£å¸¸æ–‡æœ¬")
        assert result["has_pollution"] is False
        assert result["pollution_types"] == []
        assert result["original_length"] == len("æ­£å¸¸æ–‡æœ¬")
        assert result["cleaned_length"] == len("æ­£å¸¸æ–‡æœ¬")

    def test_detect_pollution_bidirectional(self):
        """æµ‹è¯•æ£€æµ‹åŒå‘æ–‡æœ¬æ§åˆ¶å­—ç¬¦æ±¡æŸ“"""
        text = "æ–‡æœ¬\u200e\u200fä¸­é—´"
        result = self.cleaner.detect_unicode_pollution(text)
        assert result["has_pollution"] is True
        assert "bidirectional_control_chars" in result["pollution_types"]

    def test_detect_pollution_control_chars(self):
        """æµ‹è¯•æ£€æµ‹æ§åˆ¶å­—ç¬¦æ±¡æŸ“"""
        text = "æ–‡æœ¬\x00\x01\x7fä¸­é—´"
        result = self.cleaner.detect_unicode_pollution(text)
        assert result["has_pollution"] is True
        assert "control_chars" in result["pollution_types"]

    def test_detect_pollution_zero_width(self):
        """æµ‹è¯•æ£€æµ‹é›¶å®½å­—ç¬¦æ±¡æŸ“"""
        text = "æ–‡æœ¬\u200b\u200c\u200dä¸­é—´"
        result = self.cleaner.detect_unicode_pollution(text)
        assert result["has_pollution"] is True
        assert "zero_width_chars" in result["pollution_types"]

    def test_detect_pollution_multiple_types(self):
        """æµ‹è¯•æ£€æµ‹å¤šç§ç±»å‹æ±¡æŸ“"""
        text = "\u200eæ–‡æœ¬\x00\u200bä¸­é—´"
        result = self.cleaner.detect_unicode_pollution(text)
        assert result["has_pollution"] is True
        assert len(result["pollution_types"]) == 3

    def test_detect_pollution_non_string(self):
        """æµ‹è¯•æ£€æµ‹éå­—ç¬¦ä¸²è¾“å…¥"""
        result = self.cleaner.detect_unicode_pollution(12345)
        assert result["has_pollution"] is False
        assert result["pollution_types"] == []

    def test_detect_pollution_none(self):
        """æµ‹è¯•æ£€æµ‹Noneè¾“å…¥"""
        result = self.cleaner.detect_unicode_pollution(None)
        assert result["has_pollution"] is False

    def test_detect_pollution_length_difference(self):
        """æµ‹è¯•æ£€æµ‹å‰åçš„é•¿åº¦å·®å¼‚"""
        text = "æ­£å¸¸\u200e\u200b\u200dæ–‡æœ¬"
        result = self.cleaner.detect_unicode_pollution(text)
        assert result["original_length"] > result["cleaned_length"]

    # ==================== analyze_file_pollutionæµ‹è¯• ====================

    def test_analyze_file_pollution(self, sample_excel_file):
        """æµ‹è¯•åˆ†ææ–‡ä»¶æ±¡æŸ“æƒ…å†µ"""
        result = self.cleaner.analyze_file_pollution(str(sample_excel_file))
        assert "total_cells" in result
        assert "polluted_cells" in result
        assert "pollution_rate" in result
        assert isinstance(result["total_cells"], int)
        assert result["total_cells"] >= 0

    def test_analyze_file_pollution_invalid_file(self):
        """æµ‹è¯•åˆ†æä¸å­˜åœ¨çš„æ–‡ä»¶"""
        result = self.cleaner.analyze_file_pollution("nonexistent.xlsx")
        assert "error" in result

    # ==================== è¾¹ç•Œæ¡ä»¶æµ‹è¯• ====================

    def test_clean_empty_string(self):
        """æµ‹è¯•æ¸…æ´—ç©ºå­—ç¬¦ä¸²"""
        result = self.cleaner.clean_text("")
        assert result == ""

    def test_clean_whitespace_only(self):
        """æµ‹è¯•æ¸…æ´—åªæœ‰ç©ºæ ¼çš„å­—ç¬¦ä¸²"""
        result = self.cleaner.clean_text("   \t\n  ")
        assert result == ""

    def test_clean_very_long_string(self):
        """æµ‹è¯•æ¸…æ´—è¶…é•¿å­—ç¬¦ä¸²"""
        text = "A" * 10000 + "\u200e\u200f" + "B" * 10000
        result = self.cleaner.clean_text(text)
        assert len(result) == 20000
        assert result == "A" * 10000 + "B" * 10000

    def test_clean_unicode_emoji(self):
        """æµ‹è¯•æ¸…æ´—åŒ…å«emojiçš„æ–‡æœ¬"""
        text = "æ­£å¸¸æ–‡æœ¬ğŸ˜€ğŸ˜ƒğŸ˜„è¡¨æƒ…ç¬¦å·ğŸ‰ğŸŠ"
        result = self.cleaner.clean_text(text)
        # emojiä¸åº”è¯¥è¢«ç§»é™¤
        assert "ğŸ˜€" in result or "ğŸ˜€" not in text  # å–å†³äºæ­£åˆ™è¡¨è¾¾å¼

    def test_clean_mixed_language(self):
        """æµ‹è¯•æ¸…æ´—æ··åˆè¯­è¨€æ–‡æœ¬"""
        text = "ä¸­æ–‡Englishæ—¥æœ¬èªí•œêµ­Text"
        result = self.cleaner.clean_text(text)
        # æ­£å¸¸çš„å¤šè¯­è¨€å­—ç¬¦åº”è¯¥ä¿ç•™
        assert len(result) > 0


@pytest.mark.parametrize("text,expected", [
    ("Normal text", "Normal text"),
    ("\u200eText\u200f", "Text"),
    ("\x00Text\x7f", "Text"),
    ("\u200bText\u200c", "Text"),
])
def test_clean_text_parametrized(text, expected):
    """å‚æ•°åŒ–æµ‹è¯•clean_textæ–¹æ³•"""
    cleaner = UnicodeCleaner()
    result = cleaner.clean_text(text)
    assert result == expected
